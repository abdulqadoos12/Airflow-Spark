FROM bitnami/spark:3.3.2

USER root

ENV SPARK_MASTER_PORT=7077 \
SPARK_HOME=/opt/bitnami/spark \
PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin \
SPARK_LOG_DIR=/opt/spark/logs \
SPARK_MASTER_LOG=/opt/spark/logs/spark-master.out \
SPARK_WORKER_LOG=/opt/spark/logs/spark-worker.out \
SPARK_WORKER_PORT=7000 \
SPARK_MASTER="spark://spark-master:7077" \
SPARK_WORKLOAD="master"

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      sudo \
      curl \
      vim \
      unzip \
      rsync \
      openjdk-11-jdk \
      build-essential \
      software-properties-common \
      ssh && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*


RUN export SPARK_HOME
RUN export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
RUN echo 'export SPARK_HOME="/opt/bitnami/spark"' >> ~/.bashrc
RUN echo 'export PATH="$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin"' >> ~/.bashrc
RUN echo 'export SPARK_HOME="/opt/bitnami/spark"' >> /etc/environment
RUN echo 'export SPARK_HOME="/opt/bitnami/spark"' >> /etc/environment

EXPOSE 8090 7077 6066 8080




COPY ./dags/spark_etl_script_docker.py /opt/bitnami/spark


RUN mkdir -p $SPARK_LOG_DIR && \
touch $SPARK_MASTER_LOG && \
touch $SPARK_WORKER_LOG && \
ln -sf /dev/stdout $SPARK_MASTER_LOG && \
ln -sf /dev/stdout $SPARK_WORKER_LOG

COPY ./requirements_copy.txt /
RUN pip install python==3.10.12
RUN pip install -r /requirements_copy.txt